{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"},"colab":{"name":"Copy of Alexnet.ipynb","provenance":[{"file_id":"1VPgWxF6AS34NF7WIkJDWcHoo9p2WCiMt","timestamp":1616718054441}]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"appointed-wrapping"},"source":["# 1.Prepare section"],"id":"appointed-wrapping"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"saving-refrigerator","executionInfo":{"status":"ok","timestamp":1616379529545,"user_tz":-540,"elapsed":705,"user":{"displayName":"赤司一真","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihR8gDN-tMhde8NxlbokhDtrP1QqALBmurh2B32A=s64","userId":"08143384841224428648"}},"outputId":"3dd97d37-c506-4b5b-b127-315c396841aa"},"source":["import os\n","from collections import OrderedDict\n","\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import random_split\n","import torchvision.transforms as transforms\n","import cv2\n","import tqdm\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)"],"id":"saving-refrigerator","execution_count":null,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"backed-murder"},"source":["# 2.Transform section"],"id":"backed-murder"},{"cell_type":"code","metadata":{"id":"LOoX2Terr5jR"},"source":["class ComposeTransform():\n","    \"\"\"\n","    複数のTransformをまとめあげる\n","    \"\"\"\n","    def __init__(self, transforms=None):\n","        \"\"\"\n","        Parameters\n","        --------------\n","        transforms: list\n","            transformのインスタンスをリストにして渡す\n","        \"\"\"\n","        self.transforms = transforms\n","\n","    def __call__(self, x):\n","        if self.transforms:\n","            for transform in self.transforms:\n","                x = transform(x)\n","        return x\n","\n","\n","class BaseTransform():\n","    \"\"\"\n","    自作Transformの基底クラス\n","    \"\"\"\n","    def __init__(self, debug=False):\n","        self.debug = debug\n","    \n","    def __call__(self):\n","        raise NotImplementedError()\n","\n","\n","class SimpleTransform(BaseTransform):\n","    \"\"\"\n","    とりあえずのクラス\n","    よく使うものを入れておく\n","    扱う関数が増えてきたらテーマごとに分離する\n","    \"\"\"\n","    def __call__(self, x):\n","        if self.debug:\n","            # ここで途中途中のxの値を確認できるようにしたい\n","            pass\n","        x = self.pil2cv(x)\n","        x = cv2.resize(x, (227, 227))\n","        return x\n","\n","\n","    def pil2cv(self, image):\n","        ''' PIL型 -> OpenCV型 '''\n","        new_image = np.array(image, dtype=np.uint8)\n","        if new_image.ndim == 2:  # モノクロ\n","            pass\n","        elif new_image.shape[2] == 3:  # カラー\n","            new_image = cv2.cvtColor(new_image, cv2.COLOR_RGB2BGR)\n","        elif new_image.shape[2] == 4:  # 透過\n","            new_image = cv2.cvtColor(new_image, cv2.COLOR_RGBA2BGRA)\n","        return new_image"],"id":"LOoX2Terr5jR","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hybrid-groove"},"source":["# 3.Dataset section"],"id":"hybrid-groove"},{"cell_type":"markdown","metadata":{"id":"absent-syntax"},"source":["I will use given dataset in this notebook, so this section is no in use"],"id":"absent-syntax"},{"cell_type":"markdown","metadata":{"id":"synthetic-property"},"source":["# 4.Model section"],"id":"synthetic-property"},{"cell_type":"code","metadata":{"id":"substantial-eight"},"source":["NUM_CLASSES = 10\n","\n","class AlexNet(nn.Module):\n","    def __init__(self):\n","        super(AlexNet, self).__init__()\n","\n","        self.output1 = nn.Sequential (\n","            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),   # out : 55 x 55\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),   # out : 27 x 27\n","            nn.BatchNorm2d(96)\n","        )\n","\n","        self.output2 = nn.Sequential(\n","            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),   # out : 13 x 13\n","            nn.BatchNorm2d(256)\n","        )\n","\n","        self.features = nn.Sequential(\n","            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),   # out : 6 x 6\n","            nn.BatchNorm2d(256)\n","        )\n","\n","        self.classifier = nn.Sequential (\n","            nn.Linear(256 * 6 * 6, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(0.5),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(0.5),\n","            nn.Linear(4096, NUM_CLASSES),\n","        )\n","\n","\n","    def forward(self, x):\n","        x = self.output1(x)\n","        x = self.output2(x)\n","        x = self.features(x)\n","\n","        x = x.view(x.size(0), 256 * 6 * 6)   # out : 9216\n","        return  self.classifier(x)"],"id":"substantial-eight","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"surgical-bleeding"},"source":["# 5.Main function section"],"id":"surgical-bleeding"},{"cell_type":"code","metadata":{"id":"sunrise-maker"},"source":["def train_net(net, train_loader, eval_loader, optim_cls=optim.SGD, loss_fn=nn.CrossEntropyLoss(), n_iter=20, device= 'cpu'):\n","    optimizer = optim_cls(net.parameters(), lr=0.1)\n","    train_losses = []\n","    val_losses = []\n","    train_acc = []\n","    val_acc = []\n","    n = 0\n","    n_acc = 0\n","    net = net.to(device)\n","\n","    for epoch in range(n_iter):\n","        running_loss=0.0\n","        net.train()\n","        with tqdm.tqdm(train_loader) as pbar:\n","            for i, (x, label) in enumerate(pbar):\n","                x = x.to(device)\n","                label = label.to(device)\n","                h = net(x)\n","                loss = loss_fn(h, label)\n","                running_loss+=loss.item()\n","                n += len(label)\n","                _, y_pred = h.max(1)\n","                n_acc += (y_pred==label).float().sum().item()\n","\n","                # 逆伝播によるパラメータ更新\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()\n","                pbar.set_postfix(OrderedDict(\n","                    epoch= epoch+1,\n","                    loss=running_loss/(i+1), \n","                    ))\n","            train_losses.append(running_loss / len(train_loader))\n","            train_acc.append(n_acc / n)\n","            val_loss, val_acc_ = val_net(net, eval_loader, loss_fn, device=device)\n","            val_losses.append(val_loss)\n","            val_acc.append(val_acc_)\n","\n","    return train_losses, val_losses, train_acc, val_acc\n","\n","def val_net(net, val_loader, loss_fn, device= 'cpu'):\n","    net.eval()\n","    val_acc = 0\n","    val_loss = 0\n","    n = 0\n","    n_acc =0\n","    running_loss=0.0\n","    net = net.to(device)\n","    for i, (x, label) in enumerate(val_loader):\n","        x = x.to(device)\n","        label = label.to(device)\n","        h = net(x)\n","        loss = loss_fn(h, label)\n","        running_loss+=loss.item()\n","        n += len(label)\n","        _, y_pred = h.max(1)\n","        n_acc += (y_pred==label).float().sum().item()\n","    val_acc = n_acc / n\n","    val_loss = running_loss / len(val_loader)\n","    return val_loss, val_acc\n","\n","def pred_net(net, test_loader, device= 'cpu'):\n","    y_preds = []\n","    net = net.to(device)\n","    for i, x in enumerate(test_loader):\n","        x = x.to(device)\n","        h = net(x)\n","        _, y_pred = h.max(1)\n","        y_preds.append(y_pred)\n","    return torch.cat(y_preds,dim=0)"],"id":"sunrise-maker","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"increasing-ordering"},"source":["# 6.Train section"],"id":"increasing-ordering"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"collect-diving","outputId":"a5d6fa6d-aff7-434f-a2fe-065f2167a38a"},"source":["# Transform組み立て済み\n","transform = ComposeTransform([\n","    SimpleTransform(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","])\n","\n","# Dataset組み立て\n","dataset = torchvision.datasets.CIFAR10('./datasets', train=True, \n","                                         download=True, transform=transform)\n","print(dataset[0][0].size())\n","train_size = int(len(dataset)*0.8)\n","val_size = len(dataset) - train_size\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","# Dataloader組み立て\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, \n","                                           shuffle=True, num_workers=4)\n","val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, \n","                                           shuffle=True, num_workers=4)\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer',\n","           'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","# Model組み立て\n","net = AlexNet().to(device)\n","if device == 'cuda':\n","    net = nn.DataParallel(net)\n","    torch.backends.cudnn.benchmark = True\n","\n","# MainFunction実行\n","train_losses, val_losses, train_acc, val_acc= train_net(net, train_loader, val_loader, device=device)"],"id":"collect-diving","execution_count":null,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","torch.Size([3, 227, 227])\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 313/313 [01:09<00:00,  4.49it/s, epoch=1, loss=1.44]\n","100%|██████████| 313/313 [01:08<00:00,  4.55it/s, epoch=2, loss=0.941]\n","100%|██████████| 313/313 [01:09<00:00,  4.47it/s, epoch=3, loss=0.718]\n","100%|██████████| 313/313 [01:10<00:00,  4.46it/s, epoch=4, loss=0.566]\n","100%|██████████| 313/313 [01:10<00:00,  4.45it/s, epoch=5, loss=0.43]\n","100%|██████████| 313/313 [01:11<00:00,  4.40it/s, epoch=6, loss=0.317]\n","100%|██████████| 313/313 [01:10<00:00,  4.43it/s, epoch=7, loss=0.232]\n","100%|██████████| 313/313 [01:10<00:00,  4.43it/s, epoch=8, loss=0.158]\n","100%|██████████| 313/313 [01:10<00:00,  4.44it/s, epoch=9, loss=0.113]\n","100%|██████████| 313/313 [01:10<00:00,  4.43it/s, epoch=10, loss=0.0852]\n","100%|██████████| 313/313 [01:10<00:00,  4.43it/s, epoch=11, loss=0.0705]\n"," 98%|█████████▊| 307/313 [01:09<00:01,  5.02it/s, epoch=12, loss=0.0498]"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"arabic-insulation"},"source":["# 7.Validate section"],"id":"arabic-insulation"},{"cell_type":"code","metadata":{"id":"IoKgVBNZ5LdD"},"source":["plt.plot(train_losses)\n","plt.plot(val_losses)\n","plt.show()\n","print(train_acc)\n","print(val_acc)"],"id":"IoKgVBNZ5LdD","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fatal-breeding"},"source":["# 8.Test section"],"id":"fatal-breeding"},{"cell_type":"code","metadata":{"id":"vcveyLxp6euJ"},"source":["# Transform組み立て済み\n","\n","# Dataset組み立て\n","test_set = torchvision.datasets.CIFAR10('./datasets', train=False, \n","                                        download=True, transform=transform)\n","\n","# Dataloader組み立て\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=100, \n","                                          shuffle=False, num_workers=4)\n","\n","# Model組み立て済み\n","\n","# MainFunction実行\n","y_preds = pred_net(net, test_loader)\n","\n","# Postprocess\n","print(y_preds)"],"id":"vcveyLxp6euJ","execution_count":null,"outputs":[]}]}