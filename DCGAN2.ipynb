{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DCGAN2","provenance":[],"mount_file_id":"1j7cpvk9-LITIBOAwG2XTigdXTEl92mtD","authorship_tag":"ABX9TyOZltm+Sov+uVm2Wn0tCPtm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"h_cxSxYC79Ox"},"source":["# 1.Prepare section"]},{"cell_type":"markdown","metadata":{"id":"vjvYM856iwS8"},"source":["https://github.com/ayukat1016/gan_sample"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sSXGpRqLixoi","executionInfo":{"status":"ok","timestamp":1616813690867,"user_tz":-540,"elapsed":12449,"user":{"displayName":"赤司一真","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihR8gDN-tMhde8NxlbokhDtrP1QqALBmurh2B32A=s64","userId":"08143384841224428648"}},"outputId":"29c653d0-0ae8-4a95-afa9-0fa900ada89f"},"source":["import os\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torchvision\n","import torchsummary\n","import torch.utils.data\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.utils as vutils\n","import torchvision.datasets as dset\n","from torchvision.datasets import MNIST\n","import torchvision.transforms as transforms\n","\n","\n","\n","# 設定\n","workers = 2\n","batch_size=50\n","nz = 100\n","nch_g = 128\n","nch_d = 128\n","n_epoch = 10\n","lr = 0.0002\n","beta1 = 0.5\n","outf = './result_3_2-DCGAN'\n","display_interval = 600\n","\n","# 保存先ディレクトリを作成\n","try:\n","    os.makedirs(outf, exist_ok=True)\n","except OSError as error: \n","    print(error)\n","    pass\n","\n","# 乱数のシード（種）を固定\n","random.seed(0)\n","np.random.seed(0)\n","torch.manual_seed(0)\n","\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print('device:', device)\n","\n","\n","\n","!wget www.di.ens.fr/~lelarge/MNIST.tar.gz -P /content/drive/MyDrive/data_root/mnist/\n","!tar -zxvf /content/drive/MyDrive/data_root/mnist/MNIST.tar.gz\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["device: cuda:0\n","--2021-03-27 02:54:38--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n","Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n","Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n","--2021-03-27 02:54:39--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n","Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [application/x-gzip]\n","Saving to: ‘/content/drive/MyDrive/data_root/mnist/MNIST.tar.gz.1’\n","\n","MNIST.tar.gz.1          [             <=>    ]  33.20M  3.77MB/s    in 9.5s    \n","\n","2021-03-27 02:54:49 (3.49 MB/s) - ‘/content/drive/MyDrive/data_root/mnist/MNIST.tar.gz.1’ saved [34813078]\n","\n","MNIST/\n","MNIST/raw/\n","MNIST/raw/train-labels-idx1-ubyte\n","MNIST/raw/t10k-labels-idx1-ubyte.gz\n","MNIST/raw/t10k-labels-idx1-ubyte\n","MNIST/raw/t10k-images-idx3-ubyte.gz\n","MNIST/raw/train-images-idx3-ubyte\n","MNIST/raw/train-labels-idx1-ubyte.gz\n","MNIST/raw/t10k-images-idx3-ubyte\n","MNIST/raw/train-images-idx3-ubyte.gz\n","MNIST/processed/\n","MNIST/processed/training.pt\n","MNIST/processed/test.pt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lPw6Onwu8Hry"},"source":["# 2. Transform section"]},{"cell_type":"markdown","metadata":{"id":"UiqE79u88NQ0"},"source":["# 3. Dataset section"]},{"cell_type":"code","metadata":{"id":"pzKMgZZljaH-","executionInfo":{"status":"ok","timestamp":1616813690869,"user_tz":-540,"elapsed":12442,"user":{"displayName":"赤司一真","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihR8gDN-tMhde8NxlbokhDtrP1QqALBmurh2B32A=s64","userId":"08143384841224428648"}}},"source":[""],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZIa29XO58Ph6"},"source":["# 4. Model section"]},{"cell_type":"code","metadata":{"id":"_U15xLlhksBk","executionInfo":{"status":"ok","timestamp":1616813690870,"user_tz":-540,"elapsed":12435,"user":{"displayName":"赤司一真","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihR8gDN-tMhde8NxlbokhDtrP1QqALBmurh2B32A=s64","userId":"08143384841224428648"}}},"source":["class Generator(nn.Module):\n","    \"\"\"\n","    生成器Gのクラス\n","    \"\"\"\n","    def __init__(self, nz=100, nch_g=128, nch=1):\n","        \"\"\"\n","        :param nz: 入力ベクトルzの次元\n","        :param nch_g: 最終層の入力チャネル数\n","        :param nch: 出力画像のチャネル数\n","        \"\"\"\n","        super(Generator, self).__init__()\n","\n","        # ニューラルネットワークの構造を定義する\n","        self.layers = nn.ModuleDict({\n","            'layer0': nn.Sequential(\n","                nn.ConvTranspose2d(nz, nch_g * 4, 3, 1, 0),     # 転置畳み込み\n","                nn.BatchNorm2d(nch_g * 4),                      # バッチノーマライゼーション\n","                nn.ReLU()                                       # ReLU\n","            ),  # (B, nz, 1, 1) -> (B, nch_g*4, 3, 3)\n","            'layer1': nn.Sequential(\n","                nn.ConvTranspose2d(nch_g * 4, nch_g * 2, 3, 2, 0),\n","                nn.BatchNorm2d(nch_g * 2),\n","                nn.ReLU()\n","            ),  # (B, nch_g*4, 3, 3) -> (B, nch_g*2, 7, 7)\n","            'layer2': nn.Sequential(\n","                nn.ConvTranspose2d(nch_g * 2, nch_g, 4, 2, 1),\n","                nn.BatchNorm2d(nch_g),\n","                nn.ReLU()\n","            ),  # (B, nch_g*2, 7, 7) -> (B, nch_g, 14, 14)\n","            'layer3': nn.Sequential(\n","                nn.ConvTranspose2d(nch_g, nch, 4, 2, 1),\n","                nn.Tanh()\n","            )   # (B, nch_g, 14, 14) -> (B, nch, 28, 28)\n","        })\n","\n","    def forward(self, z):\n","        \"\"\"\n","        順方向の演算\n","        :param z: 入力ベクトル\n","        :return: 生成画像\n","        \"\"\"\n","        for layer in self.layers.values():  # self.layersの各層で演算を行う\n","            z = layer(z)\n","        return z"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"NYV6MrpxkzJN","executionInfo":{"status":"ok","timestamp":1616813690871,"user_tz":-540,"elapsed":12430,"user":{"displayName":"赤司一真","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihR8gDN-tMhde8NxlbokhDtrP1QqALBmurh2B32A=s64","userId":"08143384841224428648"}}},"source":["\n","class Discriminator(nn.Module):\n","    \"\"\"\n","    識別器Dのクラス\n","    \"\"\"\n","    def __init__(self, nch=1, nch_d=128):\n","        \"\"\"\n","        :param nch: 入力画像のチャネル数\n","        :param nch_d: 先頭層の出力チャネル数\n","        \"\"\"\n","        super(Discriminator, self).__init__()\n","\n","        # ニューラルネットワークの構造を定義する\n","        self.layers = nn.ModuleDict({\n","            'layer0': nn.Sequential(\n","                nn.Conv2d(nch, nch_d, 4, 2, 1),     # 畳み込み\n","                nn.LeakyReLU(negative_slope=0.2)    # leaky ReLU関数\n","            ),  # (B, nch, 28, 28) -> (B, nch_d, 14, 14)\n","            'layer1': nn.Sequential(\n","                nn.Conv2d(nch_d, nch_d * 2, 4, 2, 1),\n","                nn.BatchNorm2d(nch_d * 2),\n","                nn.LeakyReLU(negative_slope=0.2)\n","            ),  # (B, nch_d, 14, 14) -> (B, nch_d*2, 7, 7)\n","            'layer2': nn.Sequential(\n","                nn.Conv2d(nch_d * 2, nch_d * 4, 3, 2, 0),\n","                nn.BatchNorm2d(nch_d * 4),\n","                nn.LeakyReLU(negative_slope=0.2)\n","            ),  # (B, nch_d*2, 7, 7) -> (B, nch_d*4, 3, 3)\n","            'layer3': nn.Sequential(\n","                nn.Conv2d(nch_d * 4, 1, 3, 1, 0),\n","                nn.Sigmoid()    # Sigmoid関数\n","            )    \n","            # (B, nch_d*4, 3, 3) -> (B, 1, 1, 1)\n","        })\n","\n","    def forward(self, x):\n","        \"\"\"\n","        順方向の演算\n","        :param x: 本物画像あるいは生成画像\n","        :return: 識別信号\n","        \"\"\"\n","        for layer in self.layers.values():  # self.layersの各層で演算を行う\n","            x = layer(x)\n","        return x.squeeze()     # Tensorの形状を(B)に変更して戻り値とする"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"tHzLr1rRk3gc","executionInfo":{"status":"ok","timestamp":1616813690873,"user_tz":-540,"elapsed":12426,"user":{"displayName":"赤司一真","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihR8gDN-tMhde8NxlbokhDtrP1QqALBmurh2B32A=s64","userId":"08143384841224428648"}}},"source":["def weights_init(m):\n","    \"\"\"\n","    ニューラルネットワークの重みを初期化する。作成したインスタンスに対しapplyメソッドで適用する\n","    :param m: ニューラルネットワークを構成する層\n","    \"\"\"\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:            # 畳み込み層の場合\n","        m.weight.data.normal_(0.0, 0.02)\n","        m.bias.data.fill_(0)\n","    elif classname.find('Linear') != -1:        # 全結合層の場合\n","        m.weight.data.normal_(0.0, 0.02)\n","        m.bias.data.fill_(0)\n","    elif classname.find('BatchNorm') != -1:     # バッチノーマライゼーションの場合\n","        m.weight.data.normal_(1.0, 0.02)\n","        m.bias.data.fill_(0)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"veGUz-sD8R17"},"source":["# 5. Main function section"]},{"cell_type":"markdown","metadata":{"id":"GduZJM4y8cW2"},"source":["# 6. Train section"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zBdaT5tBjb4l","executionInfo":{"status":"ok","timestamp":1616813775313,"user_tz":-540,"elapsed":11406,"user":{"displayName":"赤司一真","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihR8gDN-tMhde8NxlbokhDtrP1QqALBmurh2B32A=s64","userId":"08143384841224428648"}},"outputId":"2ee1781d-ab62-4453-ff8d-c3f9e049374d"},"source":["# Transform 組み立て\n","transform=transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,)) ])\n","\n","# Dataset 組み立て\n","train_dataset = MNIST(root = './', train=True, download=True, transform=transform)\n","\n","# Dataloader　組み立て\n","dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n","                                         shuffle=True, num_workers=int(workers))\n","\n","# Model 組み立て\n","# 生成器G　ランダムベクトルから生成画像を作成する\n","netG = Generator(nz=nz, nch_g=nch_g).to(device)\n","netG.apply(weights_init)    # weights_init関数で初期化\n","# 識別器D　画像が本物画像か生成画像かを識別する\n","netD = Discriminator(nch_d=nch_d).to(device)\n","netD.apply(weights_init)\n","\n","criterion = nn.BCELoss()    # バイナリークロスエントロピー（Sigmoid関数無し）\n","\n","# 生成器のエポックごとの画像生成に使用する確認用の固定ノイズ\n","fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device)  \n","\n","# オプティマイザ−のセットアップ\n","optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 識別器D用\n","optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 生成器G用"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Generator(\n","  (layers): ModuleDict(\n","    (layer0): Sequential(\n","      (0): ConvTranspose2d(100, 512, kernel_size=(3, 3), stride=(1, 1))\n","      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (layer1): Sequential(\n","      (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2))\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (layer2): Sequential(\n","      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (layer3): Sequential(\n","      (0): ConvTranspose2d(128, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (1): Tanh()\n","    )\n","  )\n",")\n","Discriminator(\n","  (layers): ModuleDict(\n","    (layer0): Sequential(\n","      (0): Conv2d(1, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (1): LeakyReLU(negative_slope=0.2)\n","    )\n","    (layer1): Sequential(\n","      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.2)\n","    )\n","    (layer2): Sequential(\n","      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2))\n","      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.2)\n","    )\n","    (layer3): Sequential(\n","      (0): Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1))\n","      (1): Sigmoid()\n","    )\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TKW_5vGalb5a","executionInfo":{"status":"ok","timestamp":1616814340636,"user_tz":-540,"elapsed":559981,"user":{"displayName":"赤司一真","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihR8gDN-tMhde8NxlbokhDtrP1QqALBmurh2B32A=s64","userId":"08143384841224428648"}},"outputId":"884b1e9d-2825-4643-abee-354125b7e5d9"},"source":["G_losses = []\n","D_losses = []\n","D_x_out = []\n","D_G_z1_out = []\n","\n","# 学習のループ\n","for epoch in range(n_epoch):\n","    for itr, data in enumerate(dataloader):\n","        real_image = data[0].to(device)     # 本物画像\n","        sample_size = real_image.size(0)    # 画像枚数\n","        \n","        # 標準正規分布からノイズを生成\n","        noise = torch.randn(sample_size, nz, 1, 1, device=device)\n","        # 本物画像に対する識別信号の目標値「1」\n","        real_target = torch.full((sample_size,), 1., device=device)\n","        # 生成画像に対する識別信号の目標値「0」\n","        fake_target = torch.full((sample_size,), 0., device=device) \n","        \n","        ############################\n","        # 識別器Dの更新\n","        ###########################\n","        netD.zero_grad()    # 勾配の初期化\n","\n","        output = netD(real_image)   # 識別器Dで本物画像に対する識別信号を出力\n","        errD_real = criterion(output, real_target)  # 本物画像に対する識別信号の損失値\n","        D_x = output.mean().item()  # 本物画像の識別信号の平均\n","\n","        fake_image = netG(noise)    # 生成器Gでノイズから生成画像を生成\n","        \n","        output = netD(fake_image.detach())  # 識別器Dで本物画像に対する識別信号を出力\n","        errD_fake = criterion(output, fake_target)  # 生成画像に対する識別信号の損失値\n","        D_G_z1 = output.mean().item()  # 生成画像の識別信号の平均\n","\n","        errD = errD_real + errD_fake    # 識別器Dの全体の損失\n","        errD.backward()    # 誤差逆伝播\n","        optimizerD.step()   # Dのパラメーターを更新\n","\n","        ############################\n","        # 生成器Gの更新\n","        ###########################\n","        netG.zero_grad()    # 勾配の初期化\n","        \n","        output = netD(fake_image)   # 更新した識別器Dで改めて生成画像に対する識別信号を出力\n","        errG = criterion(output, real_target)   # 生成器Gの損失値。Dに生成画像を本物画像と誤認させたいため目標値は「1」\n","        errG.backward()     # 誤差逆伝播\n","        D_G_z2 = output.mean().item()  # 更新した識別器Dによる生成画像の識別信号の平均\n","\n","        optimizerG.step()   # Gのパラメータを更新\n","\n","        if itr % display_interval == 0: \n","            print('[{}/{}][{}/{}] Loss_D: {:.3f} Loss_G: {:.3f} D(x): {:.3f} D(G(z)): {:.3f}/{:.3f}'\n","                  .format(epoch + 1, n_epoch,\n","                          itr + 1, len(dataloader),\n","                          errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","\n","        if epoch == 0 and itr == 0:     # 初回に本物画像を保存する\n","            vutils.save_image(real_image, '{}/real_samples.png'.format(outf),\n","                              normalize=True, nrow=10)\n","\n","        # ログ出力用データの保存\n","        D_losses.append(errD.item())\n","        G_losses.append(errG.item())\n","        D_x_out.append(D_x)\n","        D_G_z1_out.append(D_G_z1)\n","\n","    ############################\n","    # 確認用画像の生成\n","    ############################\n","    fake_image = netG(fixed_noise)  # 1エポック終了ごとに確認用の生成画像を生成する\n","    vutils.save_image(fake_image.detach(), '{}/fake_samples_epoch_{:03d}.png'.format(outf, epoch + 1),\n","                      normalize=True, nrow=10)\n","\n","    ############################\n","    # モデルの保存\n","    ############################\n","    if (epoch + 1) % 10 == 0:   # 10エポックごとにモデルを保存する\n","        torch.save(netG.state_dict(), '{}/netG_epoch_{}.pth'.format(outf, epoch + 1))\n","        torch.save(netD.state_dict(), '{}/netD_epoch_{}.pth'.format(outf, epoch + 1))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[1/10][1/1200] Loss_D: 1.480 Loss_G: 3.511 D(x): 0.671 D(G(z)): 0.594/0.042\n","[1/10][601/1200] Loss_D: 0.589 Loss_G: 5.662 D(x): 0.978 D(G(z)): 0.393/0.005\n","[2/10][1/1200] Loss_D: 0.527 Loss_G: 1.919 D(x): 0.725 D(G(z)): 0.131/0.190\n","[2/10][601/1200] Loss_D: 0.477 Loss_G: 3.347 D(x): 0.916 D(G(z)): 0.287/0.050\n","[3/10][1/1200] Loss_D: 0.882 Loss_G: 0.505 D(x): 0.506 D(G(z)): 0.098/0.637\n","[3/10][601/1200] Loss_D: 0.536 Loss_G: 3.502 D(x): 0.946 D(G(z)): 0.338/0.039\n","[4/10][1/1200] Loss_D: 0.718 Loss_G: 3.557 D(x): 0.930 D(G(z)): 0.418/0.043\n","[4/10][601/1200] Loss_D: 0.338 Loss_G: 2.697 D(x): 0.937 D(G(z)): 0.221/0.084\n","[5/10][1/1200] Loss_D: 0.954 Loss_G: 3.349 D(x): 0.896 D(G(z)): 0.491/0.051\n","[5/10][601/1200] Loss_D: 1.347 Loss_G: 5.002 D(x): 0.983 D(G(z)): 0.647/0.015\n","[6/10][1/1200] Loss_D: 0.238 Loss_G: 2.630 D(x): 0.881 D(G(z)): 0.086/0.115\n","[6/10][601/1200] Loss_D: 0.283 Loss_G: 4.282 D(x): 0.964 D(G(z)): 0.196/0.022\n","[7/10][1/1200] Loss_D: 0.280 Loss_G: 2.991 D(x): 0.880 D(G(z)): 0.127/0.068\n","[7/10][601/1200] Loss_D: 0.259 Loss_G: 3.203 D(x): 0.906 D(G(z)): 0.126/0.055\n","[8/10][1/1200] Loss_D: 0.248 Loss_G: 4.188 D(x): 0.923 D(G(z)): 0.122/0.022\n","[8/10][601/1200] Loss_D: 0.351 Loss_G: 4.153 D(x): 0.951 D(G(z)): 0.215/0.024\n","[9/10][1/1200] Loss_D: 0.275 Loss_G: 2.387 D(x): 0.834 D(G(z)): 0.059/0.142\n","[9/10][601/1200] Loss_D: 0.771 Loss_G: 2.217 D(x): 0.562 D(G(z)): 0.064/0.169\n","[10/10][1/1200] Loss_D: 0.733 Loss_G: 4.199 D(x): 0.896 D(G(z)): 0.363/0.024\n","[10/10][601/1200] Loss_D: 0.204 Loss_G: 3.274 D(x): 0.871 D(G(z)): 0.050/0.059\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"T3GTAjor8ju9"},"source":["# 7. Validation section"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bBE9Z09UpplW","executionInfo":{"status":"ok","timestamp":1616814755975,"user_tz":-540,"elapsed":650,"user":{"displayName":"赤司一真","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihR8gDN-tMhde8NxlbokhDtrP1QqALBmurh2B32A=s64","userId":"08143384841224428648"}},"outputId":"a00538d5-7f23-47f4-c504-4bbbe3cd8d47"},"source":["random_noise = torch.randn(batch_size, nz, 1, 1, device=device)\n","print(random_noise.size())\n","print(random_noise[0])\n","image = netG(random_noise)\n","vutils.save_image(image.detach(), 'test.png',\n","                normalize=True, nrow=10)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["torch.Size([50, 100, 1, 1])\n","tensor([[[-1.5983]],\n","\n","        [[ 0.0162]],\n","\n","        [[-0.7480]],\n","\n","        [[-0.1612]],\n","\n","        [[ 1.3439]],\n","\n","        [[ 0.2485]],\n","\n","        [[-0.2551]],\n","\n","        [[ 0.9920]],\n","\n","        [[-1.0673]],\n","\n","        [[-0.4869]],\n","\n","        [[ 1.1270]],\n","\n","        [[ 2.0956]],\n","\n","        [[ 0.9354]],\n","\n","        [[-0.0955]],\n","\n","        [[ 0.5523]],\n","\n","        [[-0.9535]],\n","\n","        [[-0.4132]],\n","\n","        [[ 0.2753]],\n","\n","        [[ 0.7466]],\n","\n","        [[ 0.3286]],\n","\n","        [[-0.5231]],\n","\n","        [[-0.9538]],\n","\n","        [[-0.3091]],\n","\n","        [[-0.2148]],\n","\n","        [[ 1.7862]],\n","\n","        [[-1.2816]],\n","\n","        [[ 1.3042]],\n","\n","        [[-0.0839]],\n","\n","        [[ 0.1639]],\n","\n","        [[-0.4130]],\n","\n","        [[-1.7506]],\n","\n","        [[-0.2202]],\n","\n","        [[ 1.2037]],\n","\n","        [[-1.0356]],\n","\n","        [[-0.4874]],\n","\n","        [[ 0.3424]],\n","\n","        [[ 1.3056]],\n","\n","        [[-0.2543]],\n","\n","        [[ 0.8562]],\n","\n","        [[-0.1595]],\n","\n","        [[-0.7872]],\n","\n","        [[ 1.0997]],\n","\n","        [[-1.5787]],\n","\n","        [[-0.0686]],\n","\n","        [[ 2.2866]],\n","\n","        [[-0.3487]],\n","\n","        [[-1.0314]],\n","\n","        [[ 0.2241]],\n","\n","        [[-0.2693]],\n","\n","        [[-0.1843]],\n","\n","        [[ 0.4276]],\n","\n","        [[-0.2750]],\n","\n","        [[-1.4061]],\n","\n","        [[ 0.8799]],\n","\n","        [[ 1.5962]],\n","\n","        [[-1.1820]],\n","\n","        [[-0.5666]],\n","\n","        [[ 2.1631]],\n","\n","        [[ 0.6222]],\n","\n","        [[ 0.1041]],\n","\n","        [[ 0.4622]],\n","\n","        [[-0.1076]],\n","\n","        [[ 1.0555]],\n","\n","        [[-0.2826]],\n","\n","        [[-1.8810]],\n","\n","        [[ 1.7341]],\n","\n","        [[-0.5850]],\n","\n","        [[-0.4182]],\n","\n","        [[ 0.2486]],\n","\n","        [[-2.2314]],\n","\n","        [[-1.2567]],\n","\n","        [[-0.1661]],\n","\n","        [[ 0.2775]],\n","\n","        [[-3.0051]],\n","\n","        [[-0.9200]],\n","\n","        [[ 0.3821]],\n","\n","        [[ 1.3585]],\n","\n","        [[ 0.9690]],\n","\n","        [[ 0.2089]],\n","\n","        [[ 1.8157]],\n","\n","        [[-1.0013]],\n","\n","        [[-0.3229]],\n","\n","        [[-2.3455]],\n","\n","        [[ 0.1337]],\n","\n","        [[-1.4359]],\n","\n","        [[-0.5163]],\n","\n","        [[-1.0938]],\n","\n","        [[-0.9950]],\n","\n","        [[-0.8651]],\n","\n","        [[ 0.8037]],\n","\n","        [[ 0.5123]],\n","\n","        [[ 0.1016]],\n","\n","        [[ 1.6518]],\n","\n","        [[-0.9628]],\n","\n","        [[ 1.1368]],\n","\n","        [[ 0.3201]],\n","\n","        [[-0.1186]],\n","\n","        [[ 0.4329]],\n","\n","        [[-0.9590]],\n","\n","        [[-1.3493]]], device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"l0N8krft8l8o"},"source":["# 8. Test section"]}]}
